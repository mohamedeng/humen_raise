{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T3y21YL76U3",
        "outputId": "04597df0-efdc-4452-a8eb-7592d8b42fc4"
      },
      "id": "2T3y21YL76U3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "given-orchestra",
      "metadata": {
        "id": "given-orchestra"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "planned-nurse",
      "metadata": {
        "id": "planned-nurse"
      },
      "outputs": [],
      "source": [
        "def random_split(lis,percent):\n",
        "    import random\n",
        "    \n",
        "    l1 = []\n",
        "    l2 = []\n",
        "    sample=random.sample(range(len(lis)), int(len(lis)*percent))\n",
        "    for i in sample :\n",
        "            l1.append(lis[i])\n",
        "        \n",
        "\n",
        "    for i in range(len(lis)) : \n",
        "        if i not in sample :\n",
        "            l2.append(lis[i])\n",
        "\n",
        "    \n",
        "        \n",
        "    return l1,l2        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "specialized-orientation",
      "metadata": {
        "id": "specialized-orientation",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b67b6d81-25f0-4c1e-e376-416256074a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass Face_dataset(Dataset):\\n\\n    def __init__ (self,dir_path,photo_list,transform=None):\\n        super().__init__()\\n        self.transform = transform\\n\\n        self.y = [ int(x.split(\"_\")[0]) for x in photo_list]\\n        self.x = []\\n        self.len = len(self.y)\\n      \\n        self.y = torch.LongTensor(self.y)\\n        \\n        for photo in photo_list :\\n            self.x.append(dir_path+\"/\"+photo)\\n\\n    def __getitem__ (self,index):\\n        return (self.transform(Image.open(self.x[index]).convert(\\'RGB\\')),self.y[index])\\n    \\n    def __len__ (self):\\n        return self.len\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "\"\"\"\n",
        "class Face_dataset(Dataset):\n",
        "\n",
        "    def __init__ (self,dir_path,photo_list,transform=None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "\n",
        "        self.y = [ int(x.split(\"_\")[0]) for x in photo_list]\n",
        "        self.x = []\n",
        "        self.len = len(self.y)\n",
        "      \n",
        "        self.y = torch.LongTensor(self.y)\n",
        "        \n",
        "        for photo in photo_list :\n",
        "            self.x.append(self.transform(Image.open(dir_path+\"/\"+photo).convert('RGB')))\n",
        "\n",
        "    def __getitem__ (self,index):\n",
        "        return (self.x[index],self.y[index])\n",
        "    \n",
        "    def __len__ (self):\n",
        "        return self.len\n",
        "\"\"\"\n",
        "class Face_dataset(Dataset):\n",
        "\n",
        "    def __init__ (self,df,transform=None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "\n",
        "        self.y = list(df[\"Label\"].astype(int))\n",
        "        self.x = list(df[\"Filepath\"])\n",
        "        self.photos = []\n",
        "        print(1)\n",
        "        self.len = len(self.y)\n",
        "      \n",
        "        self.y = torch.LongTensor(self.y)\n",
        "        \n",
        "        for photo in self.x :\n",
        "            self.photos.append(self.transform(Image.open(photo).convert('RGB')))\n",
        "\n",
        "    def __getitem__ (self,index):\n",
        "        return (self.photos[index],self.y[index])\n",
        "    \n",
        "    def __len__ (self):\n",
        "        return self.len\n",
        "\"\"\"\n",
        "class Face_dataset(Dataset):\n",
        "\n",
        "    def __init__ (self,dir_path,photo_list,transform=None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "\n",
        "        self.y = [ int(x.split(\"_\")[0]) for x in photo_list]\n",
        "        self.x = []\n",
        "        self.len = len(self.y)\n",
        "      \n",
        "        self.y = torch.LongTensor(self.y)\n",
        "        \n",
        "        for photo in photo_list :\n",
        "            self.x.append(dir_path+\"/\"+photo)\n",
        "\n",
        "    def __getitem__ (self,index):\n",
        "        return (self.transform(Image.open(self.x[index]).convert('RGB')),self.y[index])\n",
        "    \n",
        "    def __len__ (self):\n",
        "        return self.len\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "photo_list = os.listdir(\"/content/drive/MyDrive/raice_detect/UTKFace\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbumtzWYgFN",
        "outputId": "e73d46da-1039-4e77-f247-a9a01ef122ca"
      },
      "id": "VVbumtzWYgFN",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Filepath                                                                            Label\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/100_0_0_20170112215240346.jpg.chip.jpg  0        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/36_1_4_20170105164808838.jpg.chip.jpg   4        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/36_1_1_20170113001658573.jpg.chip.jpg   1        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/36_1_1_20170116014305365.jpg.chip.jpg   1        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/36_1_1_20170116161213859.jpg.chip.jpg   1        1\n",
              "                                                                                            ..\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/26_1_1_20170116164012804.jpg.chip.jpg   1        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/26_1_1_20170116171052794.jpg.chip.jpg   1        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/26_1_1_20170116171823756.jpg.chip.jpg   1        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/26_1_1_20170116173239454.jpg.chip.jpg   1        1\n",
              "/content/drive/MyDrive/raice_detect/UTKFace/9_1_4_20170103213057382.jpg.chip.jpg    4        1\n",
              "Length: 4000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = []\n",
        "for photo in photo_list :\n",
        "    filepaths.append(\"/content/drive/MyDrive/raice_detect/UTKFace\"+\"/\"+photo)\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "\n",
        "labels = ((x.split(\"_\")[2]) for x in photo_list)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "image_df = pd.concat([filepaths, labels], axis=1)\n",
        "image_df['Label'] = image_df['Label'].apply(lambda x: np.NaN if x == '20170116174525125.jpg.chip.jpg' else x)\n",
        "image_df['Label'] = image_df['Label'].apply(lambda x: np.NaN if x == '4' else x)\n",
        "\n",
        "\n",
        "\n",
        "image_df = image_df.dropna(axis=0)\n",
        "\n",
        "samples = []\n",
        "\n",
        "for category in image_df['Label'].unique():\n",
        "    category_slice = image_df.query(\"Label == @category\")\n",
        "    samples.append(category_slice.sample(3000, random_state=1))\n",
        "\n",
        "image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
        "image_df[\"Label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI2KF9MTZdZx",
        "outputId": "2908c933-aff4-4308-8825-dc6413d661b8"
      },
      "id": "mI2KF9MTZdZx",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3000\n",
              "1    3000\n",
              "2    3000\n",
              "3    3000\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "clean-archive",
      "metadata": {
        "scrolled": true,
        "id": "clean-archive",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aea0235-89db-4350-c3dc-c22b822eaa56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "    transforms.Resize((64,64)),\n",
        "    \n",
        "    transforms.ToTensor(),\n",
        "     \n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
        "\n",
        "\n",
        "\n",
        "train_df, temp_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)\n",
        "\n",
        "test_df, v_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=1)\n",
        "\n",
        "\n",
        "#train_list,test_list = random_split(photo_list,0.6)\n",
        "#valid_list = train_list[:int(len(train_list)*0.3)]\n",
        "\n",
        "train_dataset = Face_dataset(train_df,train_transform)\n",
        "test_dataset = Face_dataset(test_df,train_transform)\n",
        "valid_dataset = Face_dataset(v_df,train_transform)\n",
        "\n",
        "train_loader = DataLoader (train_dataset,batch_size = 32 ,shuffle = True)\n",
        "test_loader = DataLoader (test_dataset,batch_size = 32 ,shuffle = True)\n",
        "valid_loader = DataLoader (valid_dataset,batch_size = 32 ,shuffle = True)\n",
        "\n",
        "#image_df[\"Label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "concerned-collapse",
      "metadata": {
        "id": "concerned-collapse"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "class Cnn(nn.Module):\n",
        "    def __init__ (self):\n",
        "        super().__init__()\n",
        "        # 64*64*3\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3,16,3,padding = 1)\n",
        "        self.conv2 = nn.Conv2d(16,16,3,padding = 1)\n",
        "        self.conv3 = nn.Conv2d(16,16,3,padding = 1)\n",
        "        \n",
        "        self.batch1 = nn.BatchNorm2d(16)\n",
        "        #---------------------------------\n",
        "        self.conv4 = nn.Conv2d(16,32,3,padding = 1)\n",
        "        self.conv5 = nn.Conv2d(32,32,3,padding = 1)\n",
        "        self.conv6 = nn.Conv2d(32,32,3,padding = 1)\n",
        "        \n",
        "        self.batch2 = nn.BatchNorm2d(32)\n",
        "        #---------------------------------        \n",
        "        self.conv7 = nn.Conv2d(32,64,3,padding = 1)\n",
        "        self.conv8 = nn.Conv2d(64,64,3,padding = 1)\n",
        "        self.conv9 = nn.Conv2d(64,64,3,padding = 1)\n",
        "        \n",
        "        self.batch3 = nn.BatchNorm2d(64)\n",
        "        #---------------------------------        \n",
        "        self.max = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        \n",
        "        #8*8*64\n",
        "        #---------------------------------\n",
        "        self.flat = 8*8*64\n",
        "        self.leyers = [2000,1500,500,300,150,117]\n",
        "        self.fc1 = nn.Linear(self.flat, self.leyers[0])\n",
        "        self.fc2 = nn.Linear(self.leyers[0] , self.leyers[1])\n",
        "        self.fc3 = nn.Linear(self.leyers[1],self.leyers[2])\n",
        "        self.fc4 = nn.Linear(self.leyers[2],self.leyers[3])\n",
        "        self.fc5 = nn.Linear(self.leyers[3],self.leyers[4])\n",
        "        self.fc6 = nn.Linear(self.leyers[4],self.leyers[5])\n",
        "        \n",
        "    def  Loss_Function (self,lr):\n",
        "        \n",
        "        self.criterion = nn.CrossEntropyLoss() \n",
        "        self.optimizer = optim.Adam(self.parameters(),lr)\n",
        "        \n",
        "        \n",
        "    def forward (self,x):\n",
        "        \n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.drop(x)\n",
        "        x = self.max(x)\n",
        "        x = self.batch1(x)\n",
        "        \n",
        "        \n",
        "        #--------------\n",
        "        \n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.drop(x)\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.max(x)\n",
        "        x = self.batch2(x)\n",
        "        \n",
        "        #--------------\n",
        "        \n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = F.relu(self.conv8(x))\n",
        "        x = self.drop(x)\n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = self.max(x)\n",
        "        x = self.batch3(x)\n",
        "        \n",
        "        #--------------\n",
        "        \n",
        "        x = x.view(-1,self.flat)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.drop(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x =  F.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n",
        "    \n",
        "    def trains_(self,epoch,lr,train_data,valid_data):\n",
        "    \n",
        "        self.Loss_Function(lr)\n",
        "        valid_min = np.Inf\n",
        "        for _ in range(epoch+1):\n",
        "            t_loss = 0\n",
        "            v_loss = 0\n",
        "            self.train()\n",
        "            for x,y in train_data:\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                output = self.predict(x)\n",
        "                loss = self.criterion(output,y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                t_loss+=loss.item()\n",
        "            self.eval()\n",
        "            for x,y in valid_data:\n",
        "                \n",
        "                \n",
        "                output = self.predict(x)\n",
        "                loss = self.criterion(output,y)\n",
        "                loss.backward()\n",
        "                v_loss+=loss.item()\n",
        "                \n",
        "            t_loss = t_loss/len(train_data.dataset)\n",
        "            v_loss = v_loss/len(valid_data.dataset)\n",
        "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            _, t_loss, v_loss))\n",
        "            \n",
        "            if v_loss <= valid_min:\n",
        "                \n",
        "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_min,\n",
        "                v_loss))\n",
        "                torch.save(self.state_dict(), 'model.pt')\n",
        "                valid_min = v_loss\n",
        "                \n",
        "            \n",
        "    def predict(self,x):\n",
        "        \n",
        "        output = self.forward(x)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def test(self,test_data):\n",
        "        valid_min = np.Inf\n",
        "        for _ in range(100+1):\n",
        "          t_loss = 0\n",
        "          v_loss = 0\n",
        "      \n",
        "          for x,y in test_data:\n",
        "              output = self.predict(x)\n",
        "              loss = self.criterion(output,y)\n",
        "              loss.backward()\n",
        "              v_loss+=loss.item()\n",
        "\n",
        "          v_loss = v_loss/len(test_data.dataset)\n",
        "          print('Epoch:  Validation Loss: {:.6f}'.format(\n",
        "           v_loss))\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "absolute-desperate",
      "metadata": {
        "id": "absolute-desperate",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6860ef62-5607-4325-c798-56cc766f2871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTraining Loss: 0.056070 \tValidation Loss: 0.042454\n",
            "Validation loss decreased (inf --> 0.042454).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 0.036222 \tValidation Loss: 0.041212\n",
            "Validation loss decreased (0.042454 --> 0.041212).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.027598 \tValidation Loss: 0.037568\n",
            "Validation loss decreased (0.041212 --> 0.037568).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.024644 \tValidation Loss: 0.037516\n",
            "Validation loss decreased (0.037568 --> 0.037516).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.022878 \tValidation Loss: 0.033221\n",
            "Validation loss decreased (0.037516 --> 0.033221).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.021518 \tValidation Loss: 0.026767\n",
            "Validation loss decreased (0.033221 --> 0.026767).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.020636 \tValidation Loss: 0.030310\n",
            "Epoch: 7 \tTraining Loss: 0.019763 \tValidation Loss: 0.030098\n",
            "Epoch: 8 \tTraining Loss: 0.019033 \tValidation Loss: 0.029464\n",
            "Epoch: 9 \tTraining Loss: 0.018431 \tValidation Loss: 0.028586\n",
            "Epoch: 10 \tTraining Loss: 0.017366 \tValidation Loss: 0.028100\n",
            "Epoch: 11 \tTraining Loss: 0.016738 \tValidation Loss: 0.029434\n",
            "Epoch: 12 \tTraining Loss: 0.015873 \tValidation Loss: 0.027086\n",
            "Epoch: 13 \tTraining Loss: 0.015123 \tValidation Loss: 0.024349\n",
            "Validation loss decreased (0.026767 --> 0.024349).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.014258 \tValidation Loss: 0.025661\n",
            "Epoch: 15 \tTraining Loss: 0.013349 \tValidation Loss: 0.027588\n",
            "Epoch: 16 \tTraining Loss: 0.012252 \tValidation Loss: 0.028183\n",
            "Epoch: 17 \tTraining Loss: 0.011143 \tValidation Loss: 0.026965\n",
            "Epoch: 18 \tTraining Loss: 0.010776 \tValidation Loss: 0.035387\n",
            "Epoch: 19 \tTraining Loss: 0.009737 \tValidation Loss: 0.029079\n",
            "Epoch: 20 \tTraining Loss: 0.009012 \tValidation Loss: 0.026845\n",
            "Epoch: 21 \tTraining Loss: 0.008150 \tValidation Loss: 0.043332\n",
            "Epoch: 22 \tTraining Loss: 0.007290 \tValidation Loss: 0.038970\n",
            "Epoch: 23 \tTraining Loss: 0.006599 \tValidation Loss: 0.056687\n",
            "Epoch: 24 \tTraining Loss: 0.005950 \tValidation Loss: 0.048058\n",
            "Epoch: 25 \tTraining Loss: 0.005332 \tValidation Loss: 0.043028\n",
            "Epoch: 26 \tTraining Loss: 0.005170 \tValidation Loss: 0.036720\n",
            "Epoch: 27 \tTraining Loss: 0.004279 \tValidation Loss: 0.061963\n",
            "Epoch: 28 \tTraining Loss: 0.003917 \tValidation Loss: 0.054373\n",
            "Epoch: 29 \tTraining Loss: 0.003987 \tValidation Loss: 0.047607\n",
            "Epoch: 30 \tTraining Loss: 0.003161 \tValidation Loss: 0.040351\n",
            "Epoch: 31 \tTraining Loss: 0.003078 \tValidation Loss: 0.059196\n",
            "Epoch: 32 \tTraining Loss: 0.002840 \tValidation Loss: 0.049496\n",
            "Epoch: 33 \tTraining Loss: 0.002799 \tValidation Loss: 0.053236\n",
            "Epoch: 34 \tTraining Loss: 0.002336 \tValidation Loss: 0.059617\n",
            "Epoch: 35 \tTraining Loss: 0.002282 \tValidation Loss: 0.051839\n",
            "Epoch: 36 \tTraining Loss: 0.002213 \tValidation Loss: 0.043500\n",
            "Epoch: 37 \tTraining Loss: 0.002014 \tValidation Loss: 0.065038\n",
            "Epoch: 38 \tTraining Loss: 0.002024 \tValidation Loss: 0.066831\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9915216d634c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrains_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-0f0c986eb481>\u001b[0m in \u001b[0;36mtrains_\u001b[0;34m(self, epoch, lr, train_data, valid_data)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mt_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from os.path import exists\n",
        "\n",
        "model = Cnn()\n",
        "if(exists(\"/content/model.pt\")):\n",
        "  model.load_state_dict(torch.load('model.pt'))\n",
        "else:\n",
        "  model.trains_(50,0.00005,train_loader,valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_Accuracy(model,test_data):\n",
        "  acc = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for x,y in test_data:\n",
        "    predict = model.predict(x)\n",
        "    pre=predict.data.max(1, keepdim=True)[1]\n",
        "    correct += np.sum(np.squeeze(pre.eq(y.data.view_as(pre))).cpu().numpy())\n",
        "    total += x.size(0)\n",
        "\n",
        "  print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))"
      ],
      "metadata": {
        "id": "n9aiQvRMzt5g"
      },
      "id": "n9aiQvRMzt5g",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "  print(check_Accuracy(model,test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3IsFX1Y5yk7",
        "outputId": "6856b33f-d823-4377-88b4-5d0c4bd2ebaa"
      },
      "id": "c3IsFX1Y5yk7",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 78% (1414/1800)\n",
            "None\n",
            "\n",
            "Test Accuracy: 77% (1396/1800)\n",
            "None\n",
            "\n",
            "Test Accuracy: 79% (1423/1800)\n",
            "None\n",
            "\n",
            "Test Accuracy: 78% (1405/1800)\n",
            "None\n",
            "\n",
            "Test Accuracy: 77% (1396/1800)\n",
            "None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
